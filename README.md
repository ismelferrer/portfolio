# Transcriptor y Traductor en Tiempo Real

Un sistema completo de transcripci√≥n de voz y traducci√≥n en tiempo real utilizando Node.js, Angular y Ollama para el procesamiento de modelos LLM.

## üöÄ Caracter√≠sticas

- **Transcripci√≥n en tiempo real**: Convierte voz a texto usando la API Web Speech Recognition
- **Traducci√≥n autom√°tica**: Utiliza modelos LLM a trav√©s de Ollama para traducciones precisas
- **Interfaz moderna**: UI construida con Angular y Angular Material
- **Comunicaci√≥n WebSocket**: Procesamiento en tiempo real entre frontend y backend
- **Visualizaci√≥n de audio**: Indicadores visuales del nivel de audio durante la grabaci√≥n
- **M√∫ltiples idiomas**: Soporte para m√°s de 10 idiomas diferentes
- **Dise√±o responsivo**: Funciona en dispositivos m√≥viles y de escritorio

## üìã Requisitos Previos

### Software Necesario

1. **Node.js** (v18 o superior)
   ```bash
   # Verificar versi√≥n
   node --version
   npm --version
   ```

2. **Ollama** instalado y funcionando
   ```bash
   # Instalar Ollama (Linux/macOS)
   curl -fsSL https://ollama.ai/install.sh | sh
   
   # O descargar desde: https://ollama.ai/download
   ```

3. **Modelo LLM** descargado en Ollama
   ```bash
   # Descargar modelo recomendado
   ollama pull llama3.2
   
   # Verificar modelos instalados
   ollama list
   ```

### Navegador Compatible

- **Chrome** (recomendado para mejor soporte de Web Speech API)
- **Firefox** (soporte limitado)
- **Safari** (soporte limitado)
- **Edge** (soporte b√°sico)

## üõ†Ô∏è Instalaci√≥n

### 1. Clonar o Descargar el Proyecto

```bash
# Si tienes el c√≥digo en git
git clone <repository-url>
cd transcriptor-traductor

# O extraer el archivo zip en una carpeta
```

### 2. Configurar Backend

```bash
cd backend

# Instalar dependencias
npm install

# Copiar archivo de configuraci√≥n
cp .env.example .env

# Editar configuraci√≥n si es necesario
nano .env
```

### 3. Configurar Frontend

```bash
cd ../frontend

# Instalar dependencias
npm install

# Instalar Angular CLI globalmente (si no est√° instalado)
npm install -g @angular/cli
```

### 4. Verificar Ollama

```bash
# Verificar que Ollama est√© funcionando
curl http://localhost:11434/api/tags

# Iniciar Ollama si no est√° funcionando
ollama serve
```

## üöÄ Uso

### 1. Iniciar Backend

```bash
cd backend

# Modo desarrollo (con auto-reinicio)
npm run dev

# O modo producci√≥n
npm start
```

El servidor se iniciar√° en `http://localhost:3000`

### 2. Iniciar Frontend

```bash
# En otra terminal
cd frontend

# Modo desarrollo
npm start

# O especificar host y puerto
npm run serve
```

La aplicaci√≥n estar√° disponible en `http://localhost:4200`

### 3. Usar la Aplicaci√≥n

1. **Abrir** `http://localhost:4200` en tu navegador
2. **Permitir** acceso al micr√≥fono cuando se solicite
3. **Seleccionar** idiomas de origen y destino
4. **Presionar** el bot√≥n del micr√≥fono para iniciar grabaci√≥n
5. **Hablar** claramente al micr√≥fono
6. **Presionar** nuevamente para detener y procesar
7. **Ver** la transcripci√≥n y traducci√≥n en tiempo real

## ‚öôÔ∏è Configuraci√≥n

### Variables de Entorno (Backend)

Editar `backend/.env`:

```env
# Puerto del servidor
PORT=3000

# URL de Ollama
OLLAMA_URL=http://localhost:11434

# Modelo LLM a usar
OLLAMA_MODEL=llama3.2

# Configuraciones opcionales para servicios de nube
# GOOGLE_CLOUD_PROJECT_ID=tu-proyecto-id
# AZURE_SPEECH_KEY=tu-clave-azure
```

### Configuraci√≥n del Frontend

Editar `frontend/src/environments/environment.ts`:

```typescript
export const environment = {
  production: false,
  apiUrl: 'http://localhost:3000',
  wsUrl: 'ws://localhost:3000'
};
```

## üèóÔ∏è Arquitectura

### Backend (Node.js + Express)

```
backend/
‚îú‚îÄ‚îÄ server.js              # Servidor principal
‚îú‚îÄ‚îÄ package.json           # Dependencias del backend
‚îú‚îÄ‚îÄ .env.example          # Plantilla de configuraci√≥n
‚îî‚îÄ‚îÄ uploads/              # Archivos de audio temporales
```

**Componentes principales:**
- **Servidor Express**: API REST y WebSocket
- **WebSocket Server**: Comunicaci√≥n en tiempo real
- **Integraci√≥n Ollama**: Procesamiento de traducciones
- **Manejo de Audio**: Procesamiento de archivos de audio

### Frontend (Angular + Material)

```
frontend/src/app/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ transcriptor/           # Componente principal
‚îÇ   ‚îú‚îÄ‚îÄ audio-recorder/         # Grabaci√≥n de audio
‚îÇ   ‚îî‚îÄ‚îÄ translation-display/    # Visualizaci√≥n de traducciones
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ websocket.service.ts    # Comunicaci√≥n WebSocket
‚îÇ   ‚îú‚îÄ‚îÄ audio.service.ts        # Manejo de audio
‚îÇ   ‚îî‚îÄ‚îÄ translation.service.ts  # Gesti√≥n de traducciones
‚îî‚îÄ‚îÄ app.module.ts              # Configuraci√≥n principal
```

**Caracter√≠sticas t√©cnicas:**
- **Angular 17**: Framework principal
- **Angular Material**: Componentes UI
- **WebSocket**: Comunicaci√≥n en tiempo real
- **Web Speech API**: Reconocimiento de voz del navegador
- **RxJS**: Programaci√≥n reactiva

## üîß API Endpoints

### REST API

| M√©todo | Endpoint | Descripci√≥n |
|--------|----------|-------------|
| GET | `/health` | Estado del servidor |
| POST | `/transcribe` | Transcribir archivo de audio |
| POST | `/translate` | Traducir texto |
| GET | `/languages` | Idiomas disponibles |
| GET | `/models` | Modelos Ollama disponibles |

### WebSocket Events

| Evento | Descripci√≥n |
|--------|-------------|
| `audio-chunk` | Enviar datos de audio para transcripci√≥n |
| `translate` | Solicitar traducci√≥n de texto |
| `get-models` | Obtener modelos disponibles |
| `transcription` | Recibir resultado de transcripci√≥n |
| `translation` | Recibir resultado de traducci√≥n |
| `error` | Notificaci√≥n de error |

## üêõ Soluci√≥n de Problemas

### Problemas Comunes

#### 1. Ollama no responde
```bash
# Verificar si Ollama est√° funcionando
curl http://localhost:11434/api/tags

# Reiniciar Ollama
ollama serve
```

#### 2. Error de permisos de micr√≥fono
- Asegurar HTTPS o localhost
- Verificar configuraci√≥n del navegador
- Permitir acceso al micr√≥fono en la configuraci√≥n del sitio

#### 3. WebSocket no conecta
- Verificar que el backend est√© funcionando
- Comprobar puertos (3000 para backend, 4200 para frontend)
- Revisar firewall/antivirus

#### 4. Dependencias faltantes
```bash
# Backend
cd backend && npm install

# Frontend
cd frontend && npm install

# Angular CLI global
npm install -g @angular/cli
```

### Logs de Debug

```bash
# Backend logs
cd backend && npm run dev

# Frontend logs (consola del navegador)
F12 > Console

# Ollama logs
ollama logs
```

## üöÄ Producci√≥n

### Build del Frontend

```bash
cd frontend
ng build --configuration production
```

### Servir Archivos Est√°ticos

Agregar al servidor Express:

```javascript
app.use(express.static('dist/transcriptor-frontend'));
```

### Variables de Entorno de Producci√≥n

```env
NODE_ENV=production
PORT=3000
OLLAMA_URL=http://localhost:11434
```

## ü§ù Contribuciones

1. Fork el proyecto
2. Crear rama de feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abrir Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Ver el archivo `LICENSE` para m√°s detalles.

## üôè Reconocimientos

- **Ollama**: Por la integraci√≥n de modelos LLM
- **Angular Team**: Por el framework y Angular Material
- **Web Speech API**: Por el reconocimiento de voz en navegadores
- **Node.js Community**: Por el ecosistema de herramientas

## üìû Soporte

Si tienes problemas o preguntas:

1. Revisa la secci√≥n de **Soluci√≥n de Problemas**
2. Verifica que todos los **Requisitos Previos** est√©n cumplidos
3. Consulta los logs para errores espec√≠ficos
4. Abre un issue en el repositorio del proyecto

---

**¬°Disfruta transcribiendo y traduciendo en tiempo real! üé§‚ú®**